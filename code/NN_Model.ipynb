{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of LiveA_First_NN_Model_S2020_DS_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqzvlsW5pRxb"
      },
      "source": [
        "# Dense Neural Networks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFYENpUypaH5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "01a5d574-2ac5-4811-a7aa-a59ae9bf6c50"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEKw6TdNpHb5"
      },
      "source": [
        "# get some important modules\n",
        "import pandas as pd # for data wrangling\n",
        "import numpy as np # for array calculations, some math functions\n",
        "from matplotlib import pyplot as plt #for plotting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O14_KZVpirz"
      },
      "source": [
        "# read in some data\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Spring 2020 Materials/Week 1/Module1/Script and Data/Boston Housing.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsQbDp7fppYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9cc33aee-6915-4aaa-858d-22352666ccb8"
      },
      "source": [
        "# do some EDA if you'd like\n",
        "# see the other Boston Housing EDA script\n",
        "# boxplots, scatterplots, kde plots\n",
        "df.boxplot('medv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f242aadda20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niq0gXPcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiUexTuTpysQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6e30a664-f090-47b9-95a1-d3add8f2b856"
      },
      "source": [
        "# shape\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfA7JIgcp03T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "321aa705-9d92-497b-fa78-64c360a4f36a"
      },
      "source": [
        "# column names\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
              "       'ptratio', 'b', 'lstat', 'medv'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6BcAXUsp3mH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "9665cd43-d39d-4db0-aed2-95ebc412e3a7"
      },
      "source": [
        "# column types\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "crim       float64\n",
              "zn         float64\n",
              "indus      float64\n",
              "chas         int64\n",
              "nox        float64\n",
              "rm         float64\n",
              "age        float64\n",
              "dis        float64\n",
              "rad          int64\n",
              "tax          int64\n",
              "ptratio    float64\n",
              "b          float64\n",
              "lstat      float64\n",
              "medv       float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RWxh0BOx2aW"
      },
      "source": [
        "## A very first model\n",
        "Let's fit a NN with a simple 80/20 split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R547qllqM1Y"
      },
      "source": [
        "# split our data into X and y\n",
        "y = df['medv']\n",
        "# we can use .iloc to select rows columns by index\n",
        "# this means all rows\n",
        "X = df.iloc[:,0:13]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f2eprwwVm4H"
      },
      "source": [
        "# min/max normalization\n",
        "from sklearn import preprocessing\n",
        "\n",
        "X = X.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scaled = min_max_scaler.fit_transform(X)\n",
        "X = pd.DataFrame(X_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_TZMrwbp7jT"
      },
      "source": [
        "# basic data splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# basic data holdout\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLTtJpgDqy1Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "60f76f57-1f2f-434b-b27d-ac7125061174"
      },
      "source": [
        "# check out the shape of everything\n",
        "print(\"This is the train shape:\" + str(X_train.shape))\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the train shape:(404, 13)\n",
            "(102, 13)\n",
            "(404,)\n",
            "(102,)\n",
            "(506, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8YRPyqErIKl"
      },
      "source": [
        "# let's build our first basic NN!\n",
        "# see p. 74 or so in Chollet\n",
        "# note that we haven't standardized our data yet,\n",
        "# but that's OK for our very first NN\n",
        "\n",
        "from tensorflow.keras import layers, Sequential\n",
        "\n",
        "# this simply sets up the model, \n",
        "model = Sequential() # like a blank canvas... I'm building a Neural Network\n",
        "# first hidden layer\n",
        "model.add(layers.Dense(64, #64 hidden units - 64 representations of data\n",
        "                       activation='relu', # turns negative numbers into... 0s!\n",
        "                        input_shape=(X_train.shape[1],))) # specify the input shape (only need once)\n",
        "# turn off a random 30% of the network at a time (for each weight update)\n",
        "model.add(layers.Dropout(0.3)) # random 30% turned off\n",
        "\n",
        "# second hidden layer\n",
        "model.add(layers.Dense(62, activation='relu')) # 32 representations of data, or nonlinear partial correlations\n",
        "model.add(layers.Dropout(0.1)) # turn OFF a random 10% of the network to force different branches/weights\n",
        "\n",
        "# third hidden layer\n",
        "model.add(layers.Dense(32, activation='relu')) # 32 representations of data, or nonlinear partial correlations\n",
        "model.add(layers.Dropout(0.1)) # turn OFF a random 10% of the network to force different branches/weights\n",
        "\n",
        "# fourth hidden layer\n",
        "model.add(layers.Dense(10, activation='relu')) # 32 representations of data, or nonlinear partial correlations\n",
        "model.add(layers.Dropout(0.1)) # turn OFF a random 10% of the network to force different branches/weights\n",
        "\n",
        "\n",
        "# output layer/node\n",
        "model.add(layers.Dense(1)) # the activation function here is 'linear' by default\n",
        "# linear allows for predictions between -Inf to Inf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJngDQh_rvuy"
      },
      "source": [
        "#  this compiles the model, specifies model evaluation metrics\n",
        "# but doesn't run the model yet\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEFX4EIAsSDb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68ca7af8-bccc-4ddb-d6cb-82b0cb96f924"
      },
      "source": [
        "# now run the model!\n",
        "# let's store this as \"history\"\n",
        "history = model.fit(X_train, y_train,  # train data\n",
        "          validation_data=(X_test, y_test), # validation data\n",
        "          epochs=100,  # this is a hyperparameter that can be tuned\n",
        "          batch_size=10,  # this is a hyperparameter that can be tuned\n",
        "          verbose=1) # 0 = dont show verbose, 1 = show it!\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 498.1193 - mae: 20.2886 - val_loss: 379.8402 - val_mae: 17.0722\n",
            "Epoch 2/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 295.2862 - mae: 14.3709 - val_loss: 166.8787 - val_mae: 10.0367\n",
            "Epoch 3/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 164.3703 - mae: 9.9441 - val_loss: 101.0484 - val_mae: 7.2678\n",
            "Epoch 4/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 111.9479 - mae: 8.0908 - val_loss: 82.2763 - val_mae: 6.4941\n",
            "Epoch 5/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 99.5909 - mae: 7.4657 - val_loss: 74.3763 - val_mae: 5.7743\n",
            "Epoch 6/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 78.2143 - mae: 6.5715 - val_loss: 64.8085 - val_mae: 5.5062\n",
            "Epoch 7/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 66.3969 - mae: 5.8462 - val_loss: 61.8940 - val_mae: 5.4509\n",
            "Epoch 8/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 58.2369 - mae: 5.5058 - val_loss: 62.3760 - val_mae: 5.3181\n",
            "Epoch 9/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 58.1974 - mae: 5.3832 - val_loss: 61.5573 - val_mae: 5.2779\n",
            "Epoch 10/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 52.9013 - mae: 5.3629 - val_loss: 59.6806 - val_mae: 5.1627\n",
            "Epoch 11/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 50.1209 - mae: 5.1252 - val_loss: 59.6967 - val_mae: 5.1105\n",
            "Epoch 12/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 48.9667 - mae: 5.1163 - val_loss: 54.3773 - val_mae: 5.0629\n",
            "Epoch 13/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 43.8804 - mae: 4.8459 - val_loss: 51.6340 - val_mae: 4.9751\n",
            "Epoch 14/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 45.5713 - mae: 4.7527 - val_loss: 49.9884 - val_mae: 4.8539\n",
            "Epoch 15/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 36.6741 - mae: 4.3824 - val_loss: 52.8531 - val_mae: 4.7492\n",
            "Epoch 16/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 37.4834 - mae: 4.3821 - val_loss: 47.7985 - val_mae: 4.6226\n",
            "Epoch 17/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 32.8816 - mae: 4.2689 - val_loss: 44.2244 - val_mae: 4.7170\n",
            "Epoch 18/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 34.3599 - mae: 4.4074 - val_loss: 43.3411 - val_mae: 4.4204\n",
            "Epoch 19/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 35.5354 - mae: 4.2779 - val_loss: 41.2013 - val_mae: 4.4247\n",
            "Epoch 20/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 32.9656 - mae: 4.0999 - val_loss: 39.6929 - val_mae: 4.2767\n",
            "Epoch 21/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 34.9771 - mae: 4.2157 - val_loss: 39.6903 - val_mae: 4.1428\n",
            "Epoch 22/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 32.3694 - mae: 4.0184 - val_loss: 38.2239 - val_mae: 4.1246\n",
            "Epoch 23/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 26.3321 - mae: 3.7611 - val_loss: 37.0056 - val_mae: 4.1988\n",
            "Epoch 24/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 33.6415 - mae: 4.1272 - val_loss: 36.6676 - val_mae: 4.0954\n",
            "Epoch 25/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 29.3885 - mae: 3.8651 - val_loss: 35.6940 - val_mae: 4.0774\n",
            "Epoch 26/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 28.3233 - mae: 3.7350 - val_loss: 36.3074 - val_mae: 3.9622\n",
            "Epoch 27/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 29.2806 - mae: 4.0238 - val_loss: 34.9219 - val_mae: 3.9325\n",
            "Epoch 28/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 25.8923 - mae: 3.7777 - val_loss: 35.3377 - val_mae: 3.9128\n",
            "Epoch 29/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 25.8271 - mae: 3.7803 - val_loss: 35.6873 - val_mae: 3.8862\n",
            "Epoch 30/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 29.5579 - mae: 3.8873 - val_loss: 34.0419 - val_mae: 3.8010\n",
            "Epoch 31/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 25.5698 - mae: 3.6387 - val_loss: 36.2843 - val_mae: 3.8701\n",
            "Epoch 32/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 26.5163 - mae: 3.7532 - val_loss: 33.1688 - val_mae: 3.9635\n",
            "Epoch 33/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 27.2015 - mae: 3.8198 - val_loss: 36.0132 - val_mae: 3.8457\n",
            "Epoch 34/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 26.7238 - mae: 3.8053 - val_loss: 32.2187 - val_mae: 3.6431\n",
            "Epoch 35/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 25.4231 - mae: 3.6731 - val_loss: 33.6207 - val_mae: 3.6964\n",
            "Epoch 36/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 26.3208 - mae: 3.6953 - val_loss: 35.3177 - val_mae: 3.7525\n",
            "Epoch 37/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 23.6125 - mae: 3.4892 - val_loss: 31.9967 - val_mae: 3.6198\n",
            "Epoch 38/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 24.5218 - mae: 3.5442 - val_loss: 37.0977 - val_mae: 3.8611\n",
            "Epoch 39/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 23.8715 - mae: 3.4654 - val_loss: 30.7780 - val_mae: 3.6441\n",
            "Epoch 40/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 22.6259 - mae: 3.5614 - val_loss: 33.1497 - val_mae: 3.6146\n",
            "Epoch 41/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 25.1885 - mae: 3.6192 - val_loss: 33.6119 - val_mae: 3.6256\n",
            "Epoch 42/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 24.0706 - mae: 3.6569 - val_loss: 32.9680 - val_mae: 3.5943\n",
            "Epoch 43/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 23.1299 - mae: 3.5627 - val_loss: 29.9897 - val_mae: 3.5415\n",
            "Epoch 44/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 24.5692 - mae: 3.6573 - val_loss: 31.3681 - val_mae: 3.5076\n",
            "Epoch 45/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 24.6796 - mae: 3.6204 - val_loss: 32.4291 - val_mae: 3.5491\n",
            "Epoch 46/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 24.4133 - mae: 3.6002 - val_loss: 30.5213 - val_mae: 3.4800\n",
            "Epoch 47/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 23.5924 - mae: 3.6071 - val_loss: 30.4087 - val_mae: 3.4766\n",
            "Epoch 48/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 22.4786 - mae: 3.4272 - val_loss: 28.6856 - val_mae: 3.3781\n",
            "Epoch 49/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 25.2375 - mae: 3.6564 - val_loss: 32.0183 - val_mae: 3.4594\n",
            "Epoch 50/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 23.0643 - mae: 3.4178 - val_loss: 31.1212 - val_mae: 3.4292\n",
            "Epoch 51/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 22.2969 - mae: 3.5212 - val_loss: 31.8059 - val_mae: 3.4501\n",
            "Epoch 52/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 24.4512 - mae: 3.5601 - val_loss: 28.2306 - val_mae: 3.4737\n",
            "Epoch 53/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 21.2013 - mae: 3.3681 - val_loss: 29.8701 - val_mae: 3.3674\n",
            "Epoch 54/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 24.6431 - mae: 3.5449 - val_loss: 29.9434 - val_mae: 3.3635\n",
            "Epoch 55/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 24.7923 - mae: 3.6696 - val_loss: 28.4041 - val_mae: 3.3517\n",
            "Epoch 56/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 22.5878 - mae: 3.3921 - val_loss: 27.9691 - val_mae: 3.6272\n",
            "Epoch 57/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 22.3413 - mae: 3.3646 - val_loss: 28.5440 - val_mae: 3.2946\n",
            "Epoch 58/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 24.2168 - mae: 3.5728 - val_loss: 28.1389 - val_mae: 3.2742\n",
            "Epoch 59/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 18.9438 - mae: 3.1444 - val_loss: 26.6793 - val_mae: 3.4014\n",
            "Epoch 60/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 22.3653 - mae: 3.4955 - val_loss: 30.2245 - val_mae: 3.3486\n",
            "Epoch 61/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 20.2099 - mae: 3.2638 - val_loss: 27.3995 - val_mae: 3.3118\n",
            "Epoch 62/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 20.4600 - mae: 3.3043 - val_loss: 27.6263 - val_mae: 3.3212\n",
            "Epoch 63/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 20.3398 - mae: 3.3349 - val_loss: 30.2718 - val_mae: 3.3709\n",
            "Epoch 64/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 19.8165 - mae: 3.3073 - val_loss: 27.4805 - val_mae: 3.2065\n",
            "Epoch 65/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 21.3399 - mae: 3.2635 - val_loss: 25.4736 - val_mae: 3.2404\n",
            "Epoch 66/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 19.8600 - mae: 3.2268 - val_loss: 27.1436 - val_mae: 3.1839\n",
            "Epoch 67/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 18.1253 - mae: 2.9276 - val_loss: 25.9835 - val_mae: 3.2755\n",
            "Epoch 68/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 20.1868 - mae: 3.2482 - val_loss: 25.7876 - val_mae: 3.2327\n",
            "Epoch 69/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 20.2146 - mae: 3.3447 - val_loss: 27.7527 - val_mae: 3.1885\n",
            "Epoch 70/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 19.4260 - mae: 3.1885 - val_loss: 25.7528 - val_mae: 3.2864\n",
            "Epoch 71/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 20.9855 - mae: 3.1370 - val_loss: 24.7974 - val_mae: 3.2620\n",
            "Epoch 72/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 22.0742 - mae: 3.3335 - val_loss: 25.7862 - val_mae: 3.1957\n",
            "Epoch 73/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 19.5033 - mae: 3.2517 - val_loss: 25.3674 - val_mae: 3.1304\n",
            "Epoch 74/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 20.0005 - mae: 3.2062 - val_loss: 27.0383 - val_mae: 3.1574\n",
            "Epoch 75/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 18.3895 - mae: 3.0797 - val_loss: 26.8708 - val_mae: 3.1716\n",
            "Epoch 76/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 18.9181 - mae: 3.1271 - val_loss: 28.0192 - val_mae: 3.1923\n",
            "Epoch 77/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 19.3062 - mae: 3.1231 - val_loss: 26.3920 - val_mae: 3.1025\n",
            "Epoch 78/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 19.2584 - mae: 2.9430 - val_loss: 26.4988 - val_mae: 3.1354\n",
            "Epoch 79/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 18.5096 - mae: 3.1417 - val_loss: 24.9005 - val_mae: 3.0898\n",
            "Epoch 80/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 20.8032 - mae: 3.2534 - val_loss: 25.3824 - val_mae: 3.1613\n",
            "Epoch 81/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 21.2569 - mae: 3.2852 - val_loss: 25.9373 - val_mae: 3.1586\n",
            "Epoch 82/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 17.9474 - mae: 3.0964 - val_loss: 27.1063 - val_mae: 3.1489\n",
            "Epoch 83/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 17.3319 - mae: 2.9823 - val_loss: 25.2010 - val_mae: 3.0775\n",
            "Epoch 84/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 18.2768 - mae: 3.0220 - val_loss: 25.2042 - val_mae: 3.1640\n",
            "Epoch 85/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 15.9246 - mae: 2.9136 - val_loss: 25.6030 - val_mae: 3.1162\n",
            "Epoch 86/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 18.6520 - mae: 3.1766 - val_loss: 25.0273 - val_mae: 3.3458\n",
            "Epoch 87/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 17.6378 - mae: 3.0815 - val_loss: 28.0527 - val_mae: 3.1402\n",
            "Epoch 88/100\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 20.9315 - mae: 3.2763 - val_loss: 25.2056 - val_mae: 3.0419\n",
            "Epoch 89/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 18.6057 - mae: 3.1887 - val_loss: 25.6584 - val_mae: 3.0890\n",
            "Epoch 90/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 16.2936 - mae: 2.9785 - val_loss: 24.2937 - val_mae: 3.0514\n",
            "Epoch 91/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 17.5686 - mae: 3.0721 - val_loss: 23.9090 - val_mae: 3.1317\n",
            "Epoch 92/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 15.8659 - mae: 2.8797 - val_loss: 26.1926 - val_mae: 3.0667\n",
            "Epoch 93/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 17.1678 - mae: 2.9796 - val_loss: 25.6273 - val_mae: 3.0222\n",
            "Epoch 94/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 17.0891 - mae: 3.0485 - val_loss: 24.8030 - val_mae: 3.0659\n",
            "Epoch 95/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 17.6956 - mae: 3.1150 - val_loss: 25.1577 - val_mae: 3.0864\n",
            "Epoch 96/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 16.0509 - mae: 2.9326 - val_loss: 26.8620 - val_mae: 3.1387\n",
            "Epoch 97/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 17.1647 - mae: 3.1026 - val_loss: 24.6349 - val_mae: 3.0310\n",
            "Epoch 98/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 15.2978 - mae: 2.8610 - val_loss: 23.1445 - val_mae: 3.0641\n",
            "Epoch 99/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 18.1932 - mae: 2.9935 - val_loss: 23.9815 - val_mae: 3.1068\n",
            "Epoch 100/100\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 17.8297 - mae: 3.0706 - val_loss: 24.6724 - val_mae: 3.0936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_y-0-rzvCKg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f25328c-9038-4c27-9dcf-12c97dffd7fb"
      },
      "source": [
        "\"\"\"\n",
        " Note that the call to model.fit() returns a History object. \n",
        " This object has a member history, which is a dictionary containing data \n",
        " about everything that happened\n",
        "during training. Letâ€™s look at it:\n",
        "\n",
        ">>> history_dict = history.history\n",
        ">>> history_dict.keys()\n",
        "\"\"\"\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys() \n",
        "\n",
        "# out of all of these, let's plot the val_mean_absolute_error"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTx6iyiHtpyG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "527549db-88a1-445f-8b41-9e0aa1ffe58a"
      },
      "source": [
        "# let's see the training and validation accuracy by epoch\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss'] # you can change this\n",
        "val_loss_values = history_dict['val_loss'] # you can also change this\n",
        "epochs = range(1, len(loss_values) + 1) #acc wasn't defined before\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'orange', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYC_SGeZvoYt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0071f331-f549-46e3-9b5b-613218af2937"
      },
      "source": [
        "# we can look for the min value in the validation\n",
        "# and that's how we update our model and re-rerun\n",
        "# in our case, it looks like this happens around 100 epochs\n",
        "resultDF = pd.DataFrame(history_dict)\n",
        "resultDF.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>498.119324</td>\n",
              "      <td>20.288568</td>\n",
              "      <td>379.840240</td>\n",
              "      <td>17.072229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>295.286194</td>\n",
              "      <td>14.370872</td>\n",
              "      <td>166.878708</td>\n",
              "      <td>10.036700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>164.370300</td>\n",
              "      <td>9.944109</td>\n",
              "      <td>101.048416</td>\n",
              "      <td>7.267835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>111.947876</td>\n",
              "      <td>8.090803</td>\n",
              "      <td>82.276283</td>\n",
              "      <td>6.494064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>99.590935</td>\n",
              "      <td>7.465653</td>\n",
              "      <td>74.376335</td>\n",
              "      <td>5.774340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss        mae    val_loss    val_mae\n",
              "0  498.119324  20.288568  379.840240  17.072229\n",
              "1  295.286194  14.370872  166.878708  10.036700\n",
              "2  164.370300   9.944109  101.048416   7.267835\n",
              "3  111.947876   8.090803   82.276283   6.494064\n",
              "4   99.590935   7.465653   74.376335   5.774340"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH7yaUAuxQY6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "a3e4af16-1f03-4712-8e39-a62b7393b95a"
      },
      "source": [
        "# show the row where you have a min value\n",
        "resultDF.loc[resultDF['val_loss'] == min(resultDF['val_loss'])]\n",
        "# so later on, we will re-run for what this min would be epochs\n",
        "# if you set a random seed, you'd get the same answers."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mae</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>15.297798</td>\n",
              "      <td>2.861026</td>\n",
              "      <td>23.144508</td>\n",
              "      <td>3.064058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss       mae   val_loss   val_mae\n",
              "97  15.297798  2.861026  23.144508  3.064058"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgUX2LPms8se",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a35ea134-eee1-4347-dde9-31061dc2540f"
      },
      "source": [
        "# we can show how our model fit - notice that it runs\n",
        "# for all 300 epochs - it didn't stop even if we \n",
        "# started getting overfit results\n",
        "myPreds = model.predict(X_Train)\n",
        "myActual = y_Train\n",
        "\n",
        "# import matplotlib\n",
        "plt.scatter(myPreds, myActual)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f241f09d390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryl4ZIwTwdav",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a03b0c37-4bc5-4a3c-bfb8-116e2bec5035"
      },
      "source": [
        "# we can get the results from our model\n",
        "results = model.evaluate(X_test, y_test)\n",
        "results # this shows the loss (raw value), and your metric (MAE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 22.1081 - mae: 3.0936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[22.108051300048828, 3.0936145782470703]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdFHcgTj2-p8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b2f2441f-51e8-4484-9a14-3f1bdb7b0f8a"
      },
      "source": [
        "# you can also calculate it from your results\n",
        "# left as an exercise from the students (MAE, RMSE, MAPE if not too many zeros)\n",
        "# link: https://www.dataquest.io/blog/understanding-regression-error-metrics/\n",
        "\n",
        "print(type(myPreds)) # numpy.ndarray\n",
        "print(type(myActual)) # pandas Series"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCogwoBf6NVG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "56a3efc4-e50e-42fc-ddc4-f722b67b8632"
      },
      "source": [
        "# flatten the 1-D numpy array\n",
        "myPreds = np.ndarray.flatten(myPreds)\n",
        "myPreds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24.366447 , 24.25392  , 25.62575  , 10.934474 , 19.646885 ,\n",
              "       19.6665   , 21.736908 , 20.85972  , 16.249647 , 17.167656 ,\n",
              "        7.0716753, 11.702732 , 14.313288 ,  9.490281 , 44.701405 ,\n",
              "       33.393143 , 23.675505 , 39.759857 , 32.17106  , 21.594667 ,\n",
              "       23.995909 , 21.4416   , 18.460758 , 27.461487 , 20.913113 ,\n",
              "       12.513064 , 17.876123 , 16.742496 , 39.536003 , 18.015972 ,\n",
              "       15.275333 , 17.457716 , 19.72353  , 20.447659 , 26.478317 ,\n",
              "       18.761883 , 10.045512 , 24.890438 , 13.884739 , 12.728947 ,\n",
              "       24.524637 , 19.362144 , 21.260708 , 14.4281025, 23.147799 ,\n",
              "       23.807346 , 19.14471  , 18.971594 , 13.219647 , 22.36725  ,\n",
              "       15.679651 , 16.379473 , 21.01969  , 35.55837  , 14.613085 ,\n",
              "       19.482891 , 19.267916 , 17.492275 , 12.843841 , 19.886667 ,\n",
              "       20.005013 , 20.024796 , 34.51314  , 33.79132  , 17.24121  ,\n",
              "       32.726734 , 15.745659 , 19.336857 , 13.189475 , 21.129843 ,\n",
              "       20.176384 , 21.994774 , 28.728655 , 28.444454 , 28.369518 ,\n",
              "        9.233924 , 42.356674 , 21.967852 , 25.36741  , 17.533512 ,\n",
              "       26.292887 , 18.96246  , 18.273893 , 43.283688 , 45.274754 ,\n",
              "       24.132406 , 22.322075 , 13.436421 , 26.56974  , 14.464439 ,\n",
              "       17.351    , 10.766455 , 23.48485  , 29.399157 , 21.719738 ,\n",
              "       20.125578 ,  9.02438  , 24.785215 , 13.046682 , 17.609406 ,\n",
              "       23.524212 , 20.252174 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB-Gwl1363SO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e8a1d5f6-7352-4ac2-e7c0-832acd443554"
      },
      "source": [
        "# we can put the predictions side by side\n",
        "# need to drop the index\n",
        "myPreds = pd.DataFrame(myPreds)\n",
        "myPreds.reset_index(drop=True)\n",
        "myPreds.rename(columns={0: \"MyPreds\"}, inplace=True)\n",
        "myPreds.dtypes\n",
        "myPreds.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MyPreds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24.366447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24.253920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25.625750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.934474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.646885</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     MyPreds\n",
              "0  24.366447\n",
              "1  24.253920\n",
              "2  25.625750\n",
              "3  10.934474\n",
              "4  19.646885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JamVw0Yr7Skp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "09511d12-7ab8-45ef-bfba-d7562914f4c2"
      },
      "source": [
        "# your actual predictions\n",
        "# note, I put these in a numpy array\n",
        "# since the index was being annoying\n",
        "myActual = pd.DataFrame(np.array(y_test))\n",
        "myActual.reset_index(drop=True)\n",
        "myActual.rename(columns={0: \"MyActual\"}, inplace=True)\n",
        "myActual.dtypes\n",
        "myActual.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MyActual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MyActual\n",
              "0      22.6\n",
              "1      50.0\n",
              "2      23.0\n",
              "3       8.3\n",
              "4      21.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2EKeiwl7Nz2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e0bbaf7f-ce6a-47bb-ab2f-97d0c9a3e859"
      },
      "source": [
        "allResults = pd.concat([myPreds, myActual], axis=1)\n",
        "allResults.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MyPreds</th>\n",
              "      <th>MyActual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>24.366447</td>\n",
              "      <td>22.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24.253920</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25.625750</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.934474</td>\n",
              "      <td>8.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19.646885</td>\n",
              "      <td>21.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     MyPreds  MyActual\n",
              "0  24.366447      22.6\n",
              "1  24.253920      50.0\n",
              "2  25.625750      23.0\n",
              "3  10.934474       8.3\n",
              "4  19.646885      21.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj3wT7F6-Tzd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8b9f0323-4940-41c8-d51b-a45d9be1bd66"
      },
      "source": [
        "# you can then calculate all sorts of metrics\n",
        "# on this dataframe\n",
        "allResults['AbsErr'] = abs(allResults['MyPreds'] - allResults['MyActual'])\n",
        "allResults.head()\n",
        "# now it's easy to calculate MAE\n",
        "print(np.mean(allResults['AbsErr']))\n",
        "\n",
        "# which is the same as:\n",
        "model.evaluate(X_test, y_test)\n",
        "\n",
        "# think of all the other regression metrics you can make!\n",
        "\n",
        "# I much prefer to have control of my results\n",
        "# like this! You can imagine how nice it is\n",
        "# to extract TPR, TFR and other things for a \n",
        "# classification problem\n",
        "\n",
        "# and you can also imagine how nice it is\n",
        "# for a k-fold cross-validation! \n",
        "# just need to add fold information"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.0936143276738197\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 22.1081 - mae: 3.0936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[22.108051300048828, 3.0936145782470703]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3zc5juv_VHE"
      },
      "source": [
        "# this is how we can save a .csv to our Google Drive\n",
        "allResults.to_csv('/content/drive/My Drive/Spring 2020 Materials/Week 1/Module1/Script and Data/test.csv')\n",
        "\n",
        "# if we need to make a new directory, we could do:\n",
        "# link: https://stackoverflow.com/questions/54172874/making-two-new-directory-in-google-colab-and-join-them\n",
        "import tensorflow as tf\n",
        "\n",
        "#Create a new directory (a folder) in your Drive\n",
        "tf.io.gfile.mkdir('/content/drive/My Drive/Spring 2020 Materials/Week 1/Module1/Script and Data/My First NN Results')\n",
        "allResults.to_csv('/content/drive/My Drive/Spring 2020 Materials/Week 1/Module1/Script and Data/My First NN Results/Results_NN_SimpleHoldout.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfxTrCd60TUz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "1c183745-0a43-4bf1-d3d5-cda152cd0aff"
      },
      "source": [
        "# TO DO: make it a nice subplot for training and validation\n",
        "# results, with a nice axes and a main title,\n",
        "# then save the image to your Google Drive\n",
        "# a long with a .csv of actual vs. predicted results\n",
        "\n",
        "# nice link: https://matplotlib.org/gallery/subplots_axes_and_figures/figure_title.html\n",
        "\n",
        "# specify the dimensions \n",
        "fig, axes = plt.subplots(1,2) # 1 row, 2 columns\n",
        "\n",
        "# add a main title across top\n",
        "#fig.suptitle(\"My Results\", fontsize=20)\n",
        "\n",
        "# \tval_loss\tval_mean_absolute_error\tloss\tmean_absolute_error\n",
        "\n",
        "# this makes the individual subplots\n",
        "# Training Results\n",
        "axes[0].scatter(x=y_train, y=model.predict(X_train)) #first row, first entry (left top)\n",
        "axes[0].set_xlabel(\"Actual\", fontsize=10)\n",
        "axes[0].set_ylabel(\"Predicted\",  fontsize=10)\n",
        "axes[0].set_title(\"Training\")\n",
        "# add 45 deg line\n",
        "x = np.linspace(*axes[0].get_xlim())\n",
        "axes[0].plot(x, x, color='red')\n",
        "# Validation Results\n",
        "axes[1].scatter(x=y_test, y=model.predict(X_test)) # first row, second entry (right top)\n",
        "axes[1].set_xlabel(\"Actual\", fontsize=10)\n",
        "axes[1].set_ylabel(\"Predicted\",  fontsize=10)\n",
        "axes[1].set_title(\"Validation\")\n",
        "# add 45 deg line\n",
        "x = np.linspace(*axes[1].get_xlim())\n",
        "axes[1].plot(x, x, color='red')\n",
        "\n",
        "# tight layout\n",
        "fig.tight_layout()\n",
        "\n",
        "# by adding this line of code, we can save our plot to our Google Drive\n",
        "# link: https://chartio.com/resources/tutorials/how-to-save-a-plot-to-a-file-using-matplotlib/\n",
        "plt.savefig('/content/drive/My Drive/Spring 2020 Materials/Week 1/Module1/Script and Data/My First NN Results/Results Plot.png')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUEoppaLS/wMLV56HXWBDFgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae2fHPzfxtq3"
      },
      "source": [
        "## Re-run the model for 100 epochs\n",
        "since this is the best fit of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvAu19QSxrZe"
      },
      "source": [
        "# let's try to re-run the model for 100 epochs\n",
        "# then we can save the results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2MPi1BxyUe0"
      },
      "source": [
        "## Introducing Early-Stopping\n",
        "It would be nice if our model would stop once it stops overfitting. \n",
        "\n",
        "Here's a nice link: https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSvwe--Iwbr0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6e8299b-bf79-4f6b-b324-d7fba8b64e3c"
      },
      "source": [
        "# don't forget you can also include patience (if you want)\n",
        "# simple early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', \n",
        "                   # LOOK HOW QUICK IT STOPS IF YOU DON'T USE\n",
        "                   # PATIENCE - SUBJECT TO NOISE!!!\n",
        "                   # will vary based on every problem you tackle\n",
        "                   # try a patience of 2, 5, 10, 50, 100...\n",
        "                   # what do you notice?\n",
        "                   patience=50, \n",
        "                   verbose=1)\n",
        "# fit model\n",
        "history = model.fit(X_train, y_train, \n",
        "                    validation_data=(X_test, y_test), \n",
        "                    epochs=4000, \n",
        "                    verbose=1, \n",
        "                    callbacks=[es]) #notice we won't have to manually watch it\n",
        "                    # "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 16.6967 - mae: 2.9789 - val_loss: 23.1939 - val_mae: 3.0728\n",
            "Epoch 2/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.8427 - mae: 2.8107 - val_loss: 21.3655 - val_mae: 3.0995\n",
            "Epoch 3/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.8718 - mae: 2.8037 - val_loss: 21.6387 - val_mae: 3.0531\n",
            "Epoch 4/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 17.0665 - mae: 2.9433 - val_loss: 20.9626 - val_mae: 3.0922\n",
            "Epoch 5/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 17.5880 - mae: 2.9166 - val_loss: 21.4800 - val_mae: 3.0522\n",
            "Epoch 6/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 16.5172 - mae: 2.9127 - val_loss: 21.7624 - val_mae: 3.0441\n",
            "Epoch 7/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.3547 - mae: 2.8051 - val_loss: 20.6347 - val_mae: 3.0582\n",
            "Epoch 8/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.8705 - mae: 2.9892 - val_loss: 21.2084 - val_mae: 3.0256\n",
            "Epoch 9/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.2506 - mae: 2.9298 - val_loss: 21.1025 - val_mae: 3.0170\n",
            "Epoch 10/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 18.8686 - mae: 3.0434 - val_loss: 19.8834 - val_mae: 3.0843\n",
            "Epoch 11/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 17.8156 - mae: 3.1079 - val_loss: 21.5448 - val_mae: 3.0350\n",
            "Epoch 12/4000\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 17.0739 - mae: 3.0619 - val_loss: 21.0456 - val_mae: 3.0400\n",
            "Epoch 13/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.0999 - mae: 2.9038 - val_loss: 20.5848 - val_mae: 3.0945\n",
            "Epoch 14/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.8389 - mae: 2.8533 - val_loss: 20.3484 - val_mae: 3.0658\n",
            "Epoch 15/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 17.3681 - mae: 2.9728 - val_loss: 19.5937 - val_mae: 3.1342\n",
            "Epoch 16/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.3590 - mae: 2.6856 - val_loss: 21.0750 - val_mae: 3.0356\n",
            "Epoch 17/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.6310 - mae: 2.7650 - val_loss: 20.1746 - val_mae: 3.0761\n",
            "Epoch 18/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.7543 - mae: 2.8618 - val_loss: 21.6942 - val_mae: 3.0072\n",
            "Epoch 19/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.4437 - mae: 2.7666 - val_loss: 19.7689 - val_mae: 3.0821\n",
            "Epoch 20/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.9018 - mae: 2.7609 - val_loss: 20.3013 - val_mae: 2.9969\n",
            "Epoch 21/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.8871 - mae: 2.9223 - val_loss: 21.5309 - val_mae: 2.9804\n",
            "Epoch 22/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 16.7832 - mae: 2.9743 - val_loss: 19.7082 - val_mae: 3.0433\n",
            "Epoch 23/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 17.2672 - mae: 2.9598 - val_loss: 20.0443 - val_mae: 2.9906\n",
            "Epoch 24/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 17.8618 - mae: 2.9679 - val_loss: 20.9572 - val_mae: 3.0239\n",
            "Epoch 25/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 16.6188 - mae: 2.8957 - val_loss: 20.8144 - val_mae: 3.0042\n",
            "Epoch 26/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.5562 - mae: 2.7974 - val_loss: 20.2034 - val_mae: 2.9925\n",
            "Epoch 27/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 16.5892 - mae: 3.0041 - val_loss: 20.6242 - val_mae: 2.9780\n",
            "Epoch 28/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.9995 - mae: 2.7350 - val_loss: 19.9431 - val_mae: 2.9696\n",
            "Epoch 29/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.6574 - mae: 2.8690 - val_loss: 19.8615 - val_mae: 2.9913\n",
            "Epoch 30/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.7271 - mae: 2.9082 - val_loss: 21.1902 - val_mae: 2.9935\n",
            "Epoch 31/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.9198 - mae: 2.9230 - val_loss: 20.4109 - val_mae: 2.9555\n",
            "Epoch 32/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 16.9072 - mae: 2.8728 - val_loss: 20.1392 - val_mae: 2.9612\n",
            "Epoch 33/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.5854 - mae: 2.7396 - val_loss: 20.6247 - val_mae: 2.9553\n",
            "Epoch 34/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.7695 - mae: 2.9191 - val_loss: 20.8126 - val_mae: 2.9334\n",
            "Epoch 35/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.3606 - mae: 2.9007 - val_loss: 20.3092 - val_mae: 2.9533\n",
            "Epoch 36/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 17.5365 - mae: 2.9091 - val_loss: 19.8987 - val_mae: 3.0089\n",
            "Epoch 37/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.8746 - mae: 2.8279 - val_loss: 19.1105 - val_mae: 2.9979\n",
            "Epoch 38/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.0624 - mae: 2.7752 - val_loss: 19.8390 - val_mae: 2.9682\n",
            "Epoch 39/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.5446 - mae: 2.8152 - val_loss: 21.8714 - val_mae: 2.9841\n",
            "Epoch 40/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.8048 - mae: 2.8975 - val_loss: 21.4697 - val_mae: 2.9974\n",
            "Epoch 41/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.7864 - mae: 2.8744 - val_loss: 20.8421 - val_mae: 2.9792\n",
            "Epoch 42/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.9291 - mae: 2.8358 - val_loss: 19.8588 - val_mae: 3.0208\n",
            "Epoch 43/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.3888 - mae: 2.8352 - val_loss: 20.0557 - val_mae: 3.0380\n",
            "Epoch 44/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.4061 - mae: 2.7461 - val_loss: 20.8946 - val_mae: 2.9646\n",
            "Epoch 45/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 16.1606 - mae: 2.8875 - val_loss: 20.4508 - val_mae: 2.9737\n",
            "Epoch 46/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.2194 - mae: 2.8292 - val_loss: 19.7720 - val_mae: 2.9913\n",
            "Epoch 47/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.6772 - mae: 2.9021 - val_loss: 21.6001 - val_mae: 2.9871\n",
            "Epoch 48/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.5578 - mae: 2.6256 - val_loss: 20.3646 - val_mae: 2.9810\n",
            "Epoch 49/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.2676 - mae: 2.8478 - val_loss: 20.8002 - val_mae: 2.9597\n",
            "Epoch 50/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 17.9040 - mae: 2.9525 - val_loss: 19.0594 - val_mae: 3.0440\n",
            "Epoch 51/4000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 13.1411 - mae: 2.6467 - val_loss: 20.9095 - val_mae: 2.9420\n",
            "Epoch 52/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.3499 - mae: 2.7728 - val_loss: 19.6242 - val_mae: 2.9543\n",
            "Epoch 53/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 11.5762 - mae: 2.5641 - val_loss: 19.6928 - val_mae: 2.9402\n",
            "Epoch 54/4000\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 13.0743 - mae: 2.6308 - val_loss: 20.2844 - val_mae: 2.9813\n",
            "Epoch 55/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.6404 - mae: 2.8333 - val_loss: 20.9373 - val_mae: 2.9817\n",
            "Epoch 56/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.6175 - mae: 2.6998 - val_loss: 19.2493 - val_mae: 2.9565\n",
            "Epoch 57/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.4191 - mae: 2.8499 - val_loss: 18.6236 - val_mae: 2.9815\n",
            "Epoch 58/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.7861 - mae: 2.8362 - val_loss: 19.7121 - val_mae: 2.9626\n",
            "Epoch 59/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.3276 - mae: 2.7493 - val_loss: 19.7415 - val_mae: 2.9547\n",
            "Epoch 60/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.4411 - mae: 2.8392 - val_loss: 20.9121 - val_mae: 2.9322\n",
            "Epoch 61/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 16.9112 - mae: 2.9531 - val_loss: 19.3407 - val_mae: 2.9229\n",
            "Epoch 62/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.2874 - mae: 2.6254 - val_loss: 20.4131 - val_mae: 2.9478\n",
            "Epoch 63/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 15.1690 - mae: 2.7912 - val_loss: 19.5394 - val_mae: 2.9636\n",
            "Epoch 64/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.1185 - mae: 2.8110 - val_loss: 18.4835 - val_mae: 2.9977\n",
            "Epoch 65/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.9587 - mae: 2.7926 - val_loss: 18.6387 - val_mae: 2.9405\n",
            "Epoch 66/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.3971 - mae: 2.8207 - val_loss: 21.9911 - val_mae: 2.9878\n",
            "Epoch 67/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.6552 - mae: 2.7856 - val_loss: 21.0769 - val_mae: 2.9695\n",
            "Epoch 68/4000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 14.2647 - mae: 2.8667 - val_loss: 18.9101 - val_mae: 2.9785\n",
            "Epoch 69/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.2833 - mae: 2.7894 - val_loss: 19.7094 - val_mae: 2.9217\n",
            "Epoch 70/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.3668 - mae: 2.5714 - val_loss: 19.2901 - val_mae: 2.9097\n",
            "Epoch 71/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 16.1741 - mae: 2.8729 - val_loss: 20.1216 - val_mae: 2.9662\n",
            "Epoch 72/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.9312 - mae: 2.6486 - val_loss: 18.9282 - val_mae: 2.9915\n",
            "Epoch 73/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.3052 - mae: 2.7655 - val_loss: 20.1193 - val_mae: 2.9410\n",
            "Epoch 74/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.3452 - mae: 2.7191 - val_loss: 19.7882 - val_mae: 2.9105\n",
            "Epoch 75/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.7449 - mae: 2.7934 - val_loss: 20.0873 - val_mae: 2.9450\n",
            "Epoch 76/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.1467 - mae: 2.7956 - val_loss: 18.8243 - val_mae: 2.9795\n",
            "Epoch 77/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.5668 - mae: 2.7332 - val_loss: 20.0535 - val_mae: 2.9070\n",
            "Epoch 78/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.8698 - mae: 2.7245 - val_loss: 19.8553 - val_mae: 2.9415\n",
            "Epoch 79/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.9035 - mae: 2.7333 - val_loss: 18.6045 - val_mae: 2.9951\n",
            "Epoch 80/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.1390 - mae: 2.8108 - val_loss: 20.1446 - val_mae: 2.8953\n",
            "Epoch 81/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.7933 - mae: 2.6113 - val_loss: 18.9996 - val_mae: 2.9127\n",
            "Epoch 82/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.8510 - mae: 2.6444 - val_loss: 19.6033 - val_mae: 2.9110\n",
            "Epoch 83/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.8331 - mae: 2.6017 - val_loss: 19.5313 - val_mae: 2.9174\n",
            "Epoch 84/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.7936 - mae: 2.6687 - val_loss: 18.8160 - val_mae: 2.9678\n",
            "Epoch 85/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.5301 - mae: 2.7491 - val_loss: 19.0672 - val_mae: 2.9208\n",
            "Epoch 86/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.7468 - mae: 2.6486 - val_loss: 20.0472 - val_mae: 2.9149\n",
            "Epoch 87/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.5233 - mae: 2.7568 - val_loss: 19.9708 - val_mae: 2.9184\n",
            "Epoch 88/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.5931 - mae: 2.6596 - val_loss: 18.8797 - val_mae: 2.9571\n",
            "Epoch 89/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.3671 - mae: 2.7209 - val_loss: 18.7257 - val_mae: 3.0683\n",
            "Epoch 90/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.8456 - mae: 2.6507 - val_loss: 20.6689 - val_mae: 2.9259\n",
            "Epoch 91/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.3701 - mae: 2.6280 - val_loss: 18.9155 - val_mae: 2.9549\n",
            "Epoch 92/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.1256 - mae: 2.6257 - val_loss: 21.3105 - val_mae: 2.9386\n",
            "Epoch 93/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.9145 - mae: 2.7227 - val_loss: 20.5028 - val_mae: 2.9201\n",
            "Epoch 94/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.6944 - mae: 2.6808 - val_loss: 18.7242 - val_mae: 2.9384\n",
            "Epoch 95/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.4430 - mae: 2.6381 - val_loss: 20.2859 - val_mae: 2.9184\n",
            "Epoch 96/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.1927 - mae: 2.5871 - val_loss: 19.3371 - val_mae: 2.9140\n",
            "Epoch 97/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.1655 - mae: 2.6277 - val_loss: 18.0047 - val_mae: 2.9396\n",
            "Epoch 98/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.6209 - mae: 2.7602 - val_loss: 18.8216 - val_mae: 2.8861\n",
            "Epoch 99/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.9409 - mae: 2.7246 - val_loss: 18.8022 - val_mae: 2.9200\n",
            "Epoch 100/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.0914 - mae: 2.7589 - val_loss: 18.0933 - val_mae: 2.9046\n",
            "Epoch 101/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.9682 - mae: 2.6791 - val_loss: 17.9037 - val_mae: 2.9954\n",
            "Epoch 102/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.9266 - mae: 2.7867 - val_loss: 17.9270 - val_mae: 2.8856\n",
            "Epoch 103/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.4465 - mae: 2.7012 - val_loss: 18.4889 - val_mae: 2.9170\n",
            "Epoch 104/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.1327 - mae: 2.7265 - val_loss: 19.2806 - val_mae: 2.9681\n",
            "Epoch 105/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.9095 - mae: 2.7768 - val_loss: 19.6013 - val_mae: 2.9281\n",
            "Epoch 106/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.2660 - mae: 2.6831 - val_loss: 18.9181 - val_mae: 2.9325\n",
            "Epoch 107/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.5496 - mae: 2.6128 - val_loss: 19.0203 - val_mae: 2.9370\n",
            "Epoch 108/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 15.0653 - mae: 2.7602 - val_loss: 17.9506 - val_mae: 3.0018\n",
            "Epoch 109/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.8665 - mae: 2.7269 - val_loss: 19.5166 - val_mae: 2.8942\n",
            "Epoch 110/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.4358 - mae: 2.6870 - val_loss: 19.5792 - val_mae: 2.9569\n",
            "Epoch 111/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.9816 - mae: 2.6071 - val_loss: 19.3450 - val_mae: 2.9528\n",
            "Epoch 112/4000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 13.2740 - mae: 2.6189 - val_loss: 20.1503 - val_mae: 2.9711\n",
            "Epoch 113/4000\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 13.6113 - mae: 2.6113 - val_loss: 18.9011 - val_mae: 2.9444\n",
            "Epoch 114/4000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 13.2342 - mae: 2.6490 - val_loss: 18.3256 - val_mae: 2.8852\n",
            "Epoch 115/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.7821 - mae: 2.7038 - val_loss: 17.5210 - val_mae: 2.9881\n",
            "Epoch 116/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.4403 - mae: 2.6181 - val_loss: 18.2275 - val_mae: 2.9213\n",
            "Epoch 117/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.0019 - mae: 2.5366 - val_loss: 18.0856 - val_mae: 2.8995\n",
            "Epoch 118/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.6242 - mae: 2.5599 - val_loss: 19.6676 - val_mae: 2.9139\n",
            "Epoch 119/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 11.7355 - mae: 2.5529 - val_loss: 20.7992 - val_mae: 2.9165\n",
            "Epoch 120/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.3266 - mae: 2.7636 - val_loss: 18.1867 - val_mae: 2.9974\n",
            "Epoch 121/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 14.6590 - mae: 2.7576 - val_loss: 18.6546 - val_mae: 2.9358\n",
            "Epoch 122/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.6446 - mae: 2.6125 - val_loss: 18.8334 - val_mae: 2.9439\n",
            "Epoch 123/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.9224 - mae: 2.7130 - val_loss: 18.6627 - val_mae: 2.8736\n",
            "Epoch 124/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.1646 - mae: 2.6260 - val_loss: 18.8712 - val_mae: 2.8974\n",
            "Epoch 125/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.5510 - mae: 2.6576 - val_loss: 18.0513 - val_mae: 2.9656\n",
            "Epoch 126/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.7503 - mae: 2.7098 - val_loss: 19.2941 - val_mae: 2.8816\n",
            "Epoch 127/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.1290 - mae: 2.5741 - val_loss: 19.4158 - val_mae: 2.9439\n",
            "Epoch 128/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.6594 - mae: 2.7546 - val_loss: 18.9385 - val_mae: 2.9480\n",
            "Epoch 129/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.9798 - mae: 2.5705 - val_loss: 18.7899 - val_mae: 2.9228\n",
            "Epoch 130/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.4432 - mae: 2.6305 - val_loss: 20.1761 - val_mae: 2.9224\n",
            "Epoch 131/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.1327 - mae: 2.6454 - val_loss: 18.8819 - val_mae: 2.9307\n",
            "Epoch 132/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.6012 - mae: 2.7071 - val_loss: 17.8259 - val_mae: 2.9960\n",
            "Epoch 133/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.9644 - mae: 2.7084 - val_loss: 18.4599 - val_mae: 2.9628\n",
            "Epoch 134/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.6375 - mae: 2.6729 - val_loss: 18.2893 - val_mae: 2.9254\n",
            "Epoch 135/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.1709 - mae: 2.5152 - val_loss: 18.3130 - val_mae: 2.8880\n",
            "Epoch 136/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.3815 - mae: 2.6000 - val_loss: 17.8202 - val_mae: 2.9847\n",
            "Epoch 137/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.5047 - mae: 2.6625 - val_loss: 18.0066 - val_mae: 2.9916\n",
            "Epoch 138/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.5017 - mae: 2.6398 - val_loss: 19.1365 - val_mae: 2.8775\n",
            "Epoch 139/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 11.9191 - mae: 2.5151 - val_loss: 20.6316 - val_mae: 2.9317\n",
            "Epoch 140/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 11.3016 - mae: 2.5646 - val_loss: 19.2069 - val_mae: 2.9141\n",
            "Epoch 141/4000\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 12.3732 - mae: 2.5665 - val_loss: 17.8456 - val_mae: 3.0327\n",
            "Epoch 142/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 11.9490 - mae: 2.4873 - val_loss: 19.5745 - val_mae: 2.9016\n",
            "Epoch 143/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 10.7391 - mae: 2.4387 - val_loss: 18.2637 - val_mae: 2.9190\n",
            "Epoch 144/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.8624 - mae: 2.6529 - val_loss: 17.8704 - val_mae: 2.9071\n",
            "Epoch 145/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 11.6731 - mae: 2.5062 - val_loss: 17.8890 - val_mae: 2.9463\n",
            "Epoch 146/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 11.8537 - mae: 2.5911 - val_loss: 18.8543 - val_mae: 2.9268\n",
            "Epoch 147/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.9831 - mae: 2.7022 - val_loss: 18.0204 - val_mae: 2.9648\n",
            "Epoch 148/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 12.7348 - mae: 2.6159 - val_loss: 20.5972 - val_mae: 2.9510\n",
            "Epoch 149/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.7901 - mae: 2.6542 - val_loss: 17.7590 - val_mae: 2.9175\n",
            "Epoch 150/4000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 10.0193 - mae: 2.4020 - val_loss: 17.9152 - val_mae: 2.9565\n",
            "Epoch 151/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.5875 - mae: 2.6676 - val_loss: 18.6662 - val_mae: 2.9183\n",
            "Epoch 152/4000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 12.2438 - mae: 2.6279 - val_loss: 18.5672 - val_mae: 2.9280\n",
            "Epoch 153/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 10.6736 - mae: 2.3329 - val_loss: 18.5842 - val_mae: 2.9028\n",
            "Epoch 154/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 13.6900 - mae: 2.7480 - val_loss: 18.0660 - val_mae: 2.8753\n",
            "Epoch 155/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 11.8294 - mae: 2.6191 - val_loss: 19.2082 - val_mae: 2.8801\n",
            "Epoch 156/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.7364 - mae: 2.6756 - val_loss: 17.6951 - val_mae: 2.9847\n",
            "Epoch 157/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.5762 - mae: 2.6841 - val_loss: 18.0618 - val_mae: 2.8840\n",
            "Epoch 158/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.4528 - mae: 2.5602 - val_loss: 17.5632 - val_mae: 3.0069\n",
            "Epoch 159/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 10.7957 - mae: 2.4748 - val_loss: 19.1384 - val_mae: 2.8933\n",
            "Epoch 160/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 13.5067 - mae: 2.6440 - val_loss: 18.3664 - val_mae: 2.8616\n",
            "Epoch 161/4000\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 12.6963 - mae: 2.6005 - val_loss: 18.8531 - val_mae: 2.9242\n",
            "Epoch 162/4000\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 14.1365 - mae: 2.6866 - val_loss: 19.4582 - val_mae: 2.8964\n",
            "Epoch 163/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 12.6411 - mae: 2.6134 - val_loss: 18.0444 - val_mae: 2.9144\n",
            "Epoch 164/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.9583 - mae: 2.4054 - val_loss: 18.9743 - val_mae: 2.8687\n",
            "Epoch 165/4000\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 9.6719 - mae: 2.3531 - val_loss: 18.1738 - val_mae: 2.8755\n",
            "Epoch 00165: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2NjHXIlTORo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "82e78762-ccf6-4b8b-ade9-5d0906959806"
      },
      "source": [
        "# how long did it run for? \n",
        "# let's try to extract from history.history\n",
        "x = np.array(history.epoch)\n",
        "x = max(x)\n",
        "print(\"We should re-run for this many epochs: \", x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We should re-run for this many epochs:  164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQOol33iUJUa"
      },
      "source": [
        "# later, we should try to save the model (checkpointing)\n",
        "# and we could try loading it at a later time...\n",
        "# maybe save this for Week 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3tRdnWn098P"
      },
      "source": [
        "You can grab all that plotting code from before if you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq_39G0h08q3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "fa9757c5-4d72-4f94-960d-3c6ce3eb7641"
      },
      "source": [
        "# TO DO: make it a nice subplot for training and validation\n",
        "# results, with a nice axes and a main title,\n",
        "# then save the image to your Google Drive\n",
        "# a long with a .csv of actual vs. predicted results\n",
        "\n",
        "# nice link: https://matplotlib.org/gallery/subplots_axes_and_figures/figure_title.html\n",
        "\n",
        "# specify the dimensions \n",
        "fig, axes = plt.subplots(1,2) # 1 row, 2 columns\n",
        "\n",
        "# add a main title across top\n",
        "#fig.suptitle(\"My Results\", fontsize=20)\n",
        "\n",
        "# \tval_loss\tval_mean_absolute_error\tloss\tmean_absolute_error\n",
        "\n",
        "# this makes the individual subplots\n",
        "# Training Results\n",
        "axes[0].scatter(x=y_train, y=model.predict(X_train)) #first row, first entry (left top)\n",
        "axes[0].set_xlabel(\"Actual\", fontsize=10)\n",
        "axes[0].set_ylabel(\"Predicted\",  fontsize=10)\n",
        "axes[0].set_title(\"Training\")\n",
        "# add 45 deg line\n",
        "x = np.linspace(*axes[0].get_xlim())\n",
        "axes[0].plot(x, x, color='red')\n",
        "# Validation Results\n",
        "axes[1].scatter(x=y_test, y=model.predict(X_test)) # first row, second entry (right top)\n",
        "axes[1].set_xlabel(\"Actual\", fontsize=10)\n",
        "axes[1].set_ylabel(\"Predicted\",  fontsize=10)\n",
        "axes[1].set_title(\"Validation\")\n",
        "# add 45 deg line\n",
        "x = np.linspace(*axes[1].get_xlim())\n",
        "axes[1].plot(x, x, color='red')\n",
        "\n",
        "# tight layout\n",
        "fig.tight_layout()\n",
        "\n",
        "# by adding this line of code, we can save our plot to our Google Drive\n",
        "# link: https://chartio.com/resources/tutorials/how-to-save-a-plot-to-a-file-using-matplotlib/\n",
        "plt.savefig('/content/drive/My Drive/Spring 2020 Materials/Week 1/Module1/Script and Data/My First NN Results/Results Plot_es.png')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSimlYpIGKKWUUjFJA5RSSqmY9H/5cGUPMsyXJgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6xYuSKvxxII"
      },
      "source": [
        "## Try a k-fold example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNk4fPmFseud",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6faa526e-8ad3-43bb-a3eb-c3e006aaadbc"
      },
      "source": [
        "# in the book, you will see k-fold validation examples\n",
        "# we will get there later on, \n",
        "# along with standardizing our data\n",
        "\n",
        "# as a reference, you can look at Listing 4.2 in Chollet\n",
        "k=4\n",
        "num_validation_samples = len(df) // k\n",
        "num_validation_samples\n",
        "\n",
        "# I prefer not to code this way though...\n",
        "# here's how I would do it..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "126"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVLEdkCE2xZJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "01019246-7b62-4c0d-f2ee-1da3479654a5"
      },
      "source": [
        "# peak at the data\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>b</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      crim    zn  indus  chas    nox  ...  tax  ptratio       b  lstat  medv\n",
              "0  0.00632  18.0   2.31     0  0.538  ...  296     15.3  396.90   4.98  24.0\n",
              "1  0.02731   0.0   7.07     0  0.469  ...  242     17.8  396.90   9.14  21.6\n",
              "2  0.02729   0.0   7.07     0  0.469  ...  242     17.8  392.83   4.03  34.7\n",
              "3  0.03237   0.0   2.18     0  0.458  ...  222     18.7  394.63   2.94  33.4\n",
              "4  0.06905   0.0   2.18     0  0.458  ...  222     18.7  396.90   5.33  36.2\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSMMqYfL16xe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "709a1d50-d14e-4b02-d555-f06e1575a303"
      },
      "source": [
        "# shuffle the df\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>b</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.84970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.770</td>\n",
              "      <td>6.395</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.5052</td>\n",
              "      <td>24</td>\n",
              "      <td>666</td>\n",
              "      <td>20.2</td>\n",
              "      <td>391.34</td>\n",
              "      <td>13.27</td>\n",
              "      <td>21.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.03041</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.19</td>\n",
              "      <td>0</td>\n",
              "      <td>0.515</td>\n",
              "      <td>5.895</td>\n",
              "      <td>59.6</td>\n",
              "      <td>5.6150</td>\n",
              "      <td>5</td>\n",
              "      <td>224</td>\n",
              "      <td>20.2</td>\n",
              "      <td>394.81</td>\n",
              "      <td>10.56</td>\n",
              "      <td>18.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.24103</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.38</td>\n",
              "      <td>0</td>\n",
              "      <td>0.493</td>\n",
              "      <td>6.083</td>\n",
              "      <td>43.7</td>\n",
              "      <td>5.4159</td>\n",
              "      <td>5</td>\n",
              "      <td>287</td>\n",
              "      <td>19.6</td>\n",
              "      <td>396.90</td>\n",
              "      <td>12.79</td>\n",
              "      <td>22.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.62976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>5.949</td>\n",
              "      <td>61.8</td>\n",
              "      <td>4.7075</td>\n",
              "      <td>4</td>\n",
              "      <td>307</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>8.26</td>\n",
              "      <td>20.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>73.53410</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.679</td>\n",
              "      <td>5.957</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.8026</td>\n",
              "      <td>24</td>\n",
              "      <td>666</td>\n",
              "      <td>20.2</td>\n",
              "      <td>16.45</td>\n",
              "      <td>20.62</td>\n",
              "      <td>8.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       crim   zn  indus  chas    nox  ...  tax  ptratio       b  lstat  medv\n",
              "0   3.84970  0.0  18.10     1  0.770  ...  666     20.2  391.34  13.27  21.7\n",
              "1   0.03041  0.0   5.19     0  0.515  ...  224     20.2  394.81  10.56  18.5\n",
              "2   0.24103  0.0   7.38     0  0.493  ...  287     19.6  396.90  12.79  22.2\n",
              "3   0.62976  0.0   8.14     0  0.538  ...  307     21.0  396.90   8.26  20.4\n",
              "4  73.53410  0.0  18.10     0  0.679  ...  666     20.2   16.45  20.62   8.8\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr5nuSog5H0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2866b3a7-7517-4496-fad5-6e2dfc790eaf"
      },
      "source": [
        "print(df.columns)\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
            "       'ptratio', 'b', 'lstat', 'medv'],\n",
            "      dtype='object')\n",
            "(506, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSyJkDMEdEqZ"
      },
      "source": [
        "Tthere are a bunch of loss functions that can be optimized off of, \n",
        "and a bunch of error metrics can be checked out.\n",
        "\n",
        "https://keras.io/metrics/\n",
        "https://keras.io/losses/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVuO2K4L4n_S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "213feda0-9086-415b-8577-cdc23c286f64"
      },
      "source": [
        "# kfold with code\n",
        "# link: https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "# note that the example in the link uses input_dim instead of input_shape\n",
        "from tensorflow.keras import layers, Sequential\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset as numpy array\n",
        "dataset = df.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:13] # up to incluing column 13\n",
        "Y = dataset[:,13] # column 14 (but numbered 13, cause of Python)\n",
        "\n",
        "# here's some code from before\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='loss', \n",
        "                   mode='min', \n",
        "                   # try a patience of 2, 5, 10, 50, 100...\n",
        "                   patience=10, \n",
        "                   verbose=1)\n",
        "# define 10-fold cross-validation\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "# let's define a blank space to store our error metrics\n",
        "cvscores = []\n",
        "# and also a blank place to store the epochs\n",
        "epochDF = []\n",
        "# counter \n",
        "counter = 0\n",
        "\n",
        "# start the for loop\n",
        "for train, test in kfold.split(X, Y):\n",
        "  # print counter\n",
        "  counter = counter + 1\n",
        "  print(\"Fold Index = \",counter)\n",
        "  # create the model\n",
        "  model = Sequential()\n",
        "  model.add(layers.Dense(64, input_shape=(13,)))\n",
        "  model.add(layers.Dense(8,activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  # compile the model\n",
        "  model.compile(optimizer='rmsprop', \n",
        "                loss='mae', # try mse or mae\n",
        "                metrics=['mae'])\n",
        "  # fit the model\n",
        "  history = model.fit(X[train], \n",
        "                        Y[train],\n",
        "                        epochs=100,\n",
        "                        batch_size=10,\n",
        "                        verbose=0,\n",
        "                        callbacks=[es])\n",
        "  # evaluate the model\n",
        "  scores = model.evaluate(X[test], Y[test], verbose=0)\n",
        "  # number of epochs\n",
        "  x = max(np.array(history.epoch))\n",
        "  # save the scores\n",
        "  cvscores.append(scores)\n",
        "  # save the epochs\n",
        "  epochDF.append(x)\n",
        "  print(scores, x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold Index =  1\n",
            "[4.745976448059082, 4.71177864074707] 99\n",
            "Fold Index =  2\n",
            "Epoch 00034: early stopping\n",
            "[9.620475769042969, 9.457828521728516] 33\n",
            "Fold Index =  3\n",
            "Epoch 00100: early stopping\n",
            "[6.90367317199707, 6.656145095825195] 99\n",
            "Fold Index =  4\n",
            "Epoch 00077: early stopping\n",
            "[4.013745307922363, 3.8723390102386475] 76\n",
            "Fold Index =  5\n",
            "Epoch 00078: early stopping\n",
            "[4.290441513061523, 4.208205223083496] 77\n",
            "Fold Index =  6\n",
            "Epoch 00073: early stopping\n",
            "[4.045874118804932, 4.059146881103516] 72\n",
            "Fold Index =  7\n",
            "Epoch 00056: early stopping\n",
            "[3.9855237007141113, 4.1753764152526855] 55\n",
            "Fold Index =  8\n",
            "[5.990116119384766, 6.073483467102051] 99\n",
            "Fold Index =  9\n",
            "Epoch 00079: early stopping\n",
            "[5.48539924621582, 6.020908832550049] 78\n",
            "Fold Index =  10\n",
            "Epoch 00037: early stopping\n",
            "[14.241410255432129, 13.885615348815918] 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QGQj8OIhLIq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "1bd3804f-87d3-4d5e-9cc6-372acd9a9d1b"
      },
      "source": [
        "# this shows an index of all records in train\n",
        "print(train.shape)\n",
        "print(X[train].shape)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(456,)\n",
            "(456, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1,   2,   3,   4,   5,   7,   8,   9,  10,  11,  12,  13,  14,\n",
              "        15,  16,  17,  18,  19,  20,  21,  22,  24,  26,  27,  28,  29,\n",
              "        30,  31,  32,  33,  34,  35,  36,  37,  39,  40,  41,  43,  45,\n",
              "        46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
              "        59,  60,  61,  62,  63,  64,  65,  66,  69,  70,  71,  73,  74,\n",
              "        76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
              "        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
              "       102, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116,\n",
              "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
              "       130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143,\n",
              "       144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157,\n",
              "       158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171,\n",
              "       172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 184, 186, 187,\n",
              "       188, 190, 192, 193, 194, 195, 197, 198, 199, 200, 202, 203, 204,\n",
              "       205, 206, 207, 208, 209, 210, 212, 213, 214, 215, 216, 217, 219,\n",
              "       220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n",
              "       233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245,\n",
              "       246, 247, 248, 249, 252, 253, 254, 255, 256, 257, 258, 259, 261,\n",
              "       262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
              "       276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288,\n",
              "       289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302,\n",
              "       303, 304, 305, 306, 307, 308, 309, 310, 313, 314, 315, 316, 317,\n",
              "       318, 319, 320, 321, 322, 323, 324, 326, 327, 328, 329, 330, 331,\n",
              "       332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 344, 346,\n",
              "       347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360,\n",
              "       361, 362, 363, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374,\n",
              "       375, 376, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388,\n",
              "       389, 390, 393, 394, 395, 396, 397, 399, 400, 401, 402, 403, 404,\n",
              "       405, 406, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418,\n",
              "       419, 420, 421, 422, 423, 424, 425, 426, 427, 429, 430, 431, 433,\n",
              "       434, 435, 436, 438, 439, 440, 441, 442, 443, 445, 446, 447, 449,\n",
              "       450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
              "       463, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475, 476,\n",
              "       477, 478, 479, 480, 481, 482, 483, 484, 485, 487, 488, 489, 490,\n",
              "       491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 503, 504,\n",
              "       505])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALDProurhaoW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4a935102-0fc5-48c5-fd38-bd7236bb44cd"
      },
      "source": [
        "# this shows an index of all records in test\n",
        "print(test.shape)\n",
        "print(X[test].shape)\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50,)\n",
            "(50, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   6,  23,  25,  38,  42,  44,  67,  68,  72,  75, 103, 112,\n",
              "       137, 152, 167, 175, 183, 185, 189, 191, 196, 201, 211, 218, 250,\n",
              "       251, 260, 275, 290, 311, 312, 325, 343, 345, 348, 366, 383, 391,\n",
              "       392, 398, 407, 428, 432, 437, 444, 448, 470, 486, 502])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jTRa4FDSwpJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "4a646840-f51e-40e9-bd61-f31d42971c2a"
      },
      "source": [
        "# could also save the datasets as we went along if we wanted to\n",
        "# we could also put this in a pandas dataframe for analysis\n",
        "resultDF = pd.DataFrame(cvscores)\n",
        "# add the epochs it took\n",
        "resultDF['epochs'] = epochDF\n",
        "# change column names\n",
        "resultDF.columns = ['loss', 'mae', 'epochs']\n",
        "# show the results!\n",
        "resultDF # WHOA! one is real bad..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>epochs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.745976</td>\n",
              "      <td>4.711779</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.620476</td>\n",
              "      <td>9.457829</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.903673</td>\n",
              "      <td>6.656145</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.013745</td>\n",
              "      <td>3.872339</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.290442</td>\n",
              "      <td>4.208205</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.045874</td>\n",
              "      <td>4.059147</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.985524</td>\n",
              "      <td>4.175376</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.990116</td>\n",
              "      <td>6.073483</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5.485399</td>\n",
              "      <td>6.020909</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>14.241410</td>\n",
              "      <td>13.885615</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss        mae  epochs\n",
              "0   4.745976   4.711779      99\n",
              "1   9.620476   9.457829      33\n",
              "2   6.903673   6.656145      99\n",
              "3   4.013745   3.872339      76\n",
              "4   4.290442   4.208205      77\n",
              "5   4.045874   4.059147      72\n",
              "6   3.985524   4.175376      55\n",
              "7   5.990116   6.073483      99\n",
              "8   5.485399   6.020909      78\n",
              "9  14.241410  13.885615      36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8vEYDm07QHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a5d9c6dd-c66c-4244-c2f7-fa7dcfaf3059"
      },
      "source": [
        "# now you can calculate average(MAE)\n",
        "print(round(np.mean(resultDF['mae']),2))\n",
        "# show the std dev\n",
        "print(round(np.std(resultDF['mae']),2))\n",
        "# as well as the number of epochs\n",
        "print(np.mean(resultDF['epochs']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.31\n",
            "3.0\n",
            "72.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc2oX_mNoXEW"
      },
      "source": [
        "# Model checkpointing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrtl6UNDjYo0"
      },
      "source": [
        "# Implement this model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp6Bm4hwjYHV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ef92e68-6abe-4502-cddc-b6abe2b2bd7b"
      },
      "source": [
        "# kfold with code\n",
        "# link: https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "# note that the example in the link uses input_dim instead of input_shape\n",
        "\n",
        "from tensorflow.keras import layers, Sequential\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load dataset as numpy array\n",
        "dataset = df.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:13] # up to incluing column 13\n",
        "Y = dataset[:,13] # column 14 (but numbered 13, cause of Python)\n",
        "\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(64, input_shape=(13,)))\n",
        "model.add(layers.Dense(8,activation='relu'))\n",
        "model.add(layers.Dense(1))\n",
        "# compile the model\n",
        "model.compile(optimizer='rmsprop', \n",
        "              loss='mae', # try mse or mae\n",
        "              metrics=['mae'])\n",
        "# fit the model\n",
        "history = model.fit(X, \n",
        "                    Y,\n",
        "                    epochs=1000,\n",
        "                    batch_size=10,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1,\n",
        "                    callbacks=[es])\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y, verbose=0)\n",
        "# number of epochs\n",
        "x = max(np.array(history.epoch))\n",
        "print(scores, x)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 13.5622 - mae: 13.7041 - val_loss: 20.3785 - val_mae: 20.2159\n",
            "Epoch 2/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 11.5574 - mae: 11.3795 - val_loss: 10.2139 - val_mae: 9.9932\n",
            "Epoch 3/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 10.6642 - mae: 10.6199 - val_loss: 12.7553 - val_mae: 13.2596\n",
            "Epoch 4/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 10.2381 - mae: 10.1583 - val_loss: 8.8256 - val_mae: 8.6431\n",
            "Epoch 5/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 9.8781 - mae: 9.7934 - val_loss: 8.1602 - val_mae: 8.0315\n",
            "Epoch 6/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 9.8233 - mae: 9.8752 - val_loss: 5.5649 - val_mae: 5.5544\n",
            "Epoch 7/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 10.2392 - mae: 10.2277 - val_loss: 5.4704 - val_mae: 5.5417\n",
            "Epoch 8/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 10.2543 - mae: 10.2313 - val_loss: 5.9608 - val_mae: 5.8187\n",
            "Epoch 9/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 9.9630 - mae: 9.9951 - val_loss: 9.6430 - val_mae: 10.1650\n",
            "Epoch 10/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 9.1043 - mae: 9.1621 - val_loss: 10.2472 - val_mae: 10.5390\n",
            "Epoch 11/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 9.3809 - mae: 9.4216 - val_loss: 17.3541 - val_mae: 17.8862\n",
            "Epoch 12/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 9.2788 - mae: 9.0800 - val_loss: 9.2647 - val_mae: 9.1536\n",
            "Epoch 13/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 9.1194 - mae: 9.1187 - val_loss: 8.8761 - val_mae: 9.1922\n",
            "Epoch 14/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 9.8447 - mae: 9.8550 - val_loss: 11.3293 - val_mae: 11.6581\n",
            "Epoch 15/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 8.8888 - mae: 8.8462 - val_loss: 6.5973 - val_mae: 6.4493\n",
            "Epoch 16/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 8.4737 - mae: 8.5405 - val_loss: 7.3297 - val_mae: 7.2599\n",
            "Epoch 17/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 9.0775 - mae: 9.0579 - val_loss: 5.4177 - val_mae: 5.6262\n",
            "Epoch 18/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 9.0641 - mae: 9.0990 - val_loss: 5.9028 - val_mae: 6.2000\n",
            "Epoch 19/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 8.4998 - mae: 8.5544 - val_loss: 5.4880 - val_mae: 5.6429\n",
            "Epoch 20/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 9.3635 - mae: 9.4431 - val_loss: 12.4203 - val_mae: 12.1614\n",
            "Epoch 21/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 8.6329 - mae: 8.6499 - val_loss: 10.8665 - val_mae: 11.2218\n",
            "Epoch 22/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 8.5845 - mae: 8.6348 - val_loss: 7.8413 - val_mae: 8.3051\n",
            "Epoch 23/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 8.2898 - mae: 8.2403 - val_loss: 7.5185 - val_mae: 7.7414\n",
            "Epoch 24/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 8.4543 - mae: 8.3896 - val_loss: 6.8867 - val_mae: 7.3757\n",
            "Epoch 25/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 8.4430 - mae: 8.4892 - val_loss: 9.7821 - val_mae: 9.9774\n",
            "Epoch 26/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 7.5129 - mae: 7.5514 - val_loss: 7.6855 - val_mae: 7.8821\n",
            "Epoch 27/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 7.5819 - mae: 7.5172 - val_loss: 4.5123 - val_mae: 4.3762\n",
            "Epoch 28/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 7.7921 - mae: 7.8649 - val_loss: 4.3993 - val_mae: 4.2864\n",
            "Epoch 29/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 7.1563 - mae: 7.0818 - val_loss: 10.3082 - val_mae: 10.3920\n",
            "Epoch 30/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 7.9518 - mae: 7.9102 - val_loss: 5.6369 - val_mae: 5.4356\n",
            "Epoch 31/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 7.4720 - mae: 7.4028 - val_loss: 3.7546 - val_mae: 3.8199\n",
            "Epoch 32/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 7.4489 - mae: 7.4418 - val_loss: 3.8824 - val_mae: 3.8042\n",
            "Epoch 33/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 7.1011 - mae: 7.0792 - val_loss: 3.9337 - val_mae: 4.0450\n",
            "Epoch 34/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 7.3568 - mae: 7.2437 - val_loss: 4.7666 - val_mae: 4.6586\n",
            "Epoch 35/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 7.2001 - mae: 7.1750 - val_loss: 7.2227 - val_mae: 7.0655\n",
            "Epoch 36/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.5161 - mae: 6.5411 - val_loss: 9.0762 - val_mae: 9.4446\n",
            "Epoch 37/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 7.3484 - mae: 7.3383 - val_loss: 8.2932 - val_mae: 8.0656\n",
            "Epoch 38/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.7453 - mae: 6.7558 - val_loss: 11.9300 - val_mae: 11.6262\n",
            "Epoch 39/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 6.8846 - mae: 6.9430 - val_loss: 6.7659 - val_mae: 6.7106\n",
            "Epoch 40/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.5038 - mae: 6.5083 - val_loss: 9.7603 - val_mae: 9.7216\n",
            "Epoch 41/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 6.3648 - mae: 6.3453 - val_loss: 5.2978 - val_mae: 5.6373\n",
            "Epoch 42/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.2704 - mae: 6.1559 - val_loss: 8.1312 - val_mae: 8.5657\n",
            "Epoch 43/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.4383 - mae: 6.4487 - val_loss: 5.9974 - val_mae: 5.8289\n",
            "Epoch 44/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.1340 - mae: 6.1464 - val_loss: 5.7305 - val_mae: 5.5925\n",
            "Epoch 45/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.2131 - mae: 6.1668 - val_loss: 6.8657 - val_mae: 6.8019\n",
            "Epoch 46/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.3308 - mae: 6.3144 - val_loss: 5.2250 - val_mae: 5.0835\n",
            "Epoch 47/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.2537 - mae: 6.3023 - val_loss: 4.3591 - val_mae: 4.5257\n",
            "Epoch 48/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 6.4431 - mae: 6.4883 - val_loss: 5.0945 - val_mae: 4.8948\n",
            "Epoch 49/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.8992 - mae: 5.8849 - val_loss: 5.5079 - val_mae: 5.6000\n",
            "Epoch 50/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.7695 - mae: 5.7839 - val_loss: 6.7212 - val_mae: 7.0423\n",
            "Epoch 51/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.8929 - mae: 5.9246 - val_loss: 12.5942 - val_mae: 12.4699\n",
            "Epoch 52/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.4113 - mae: 6.3630 - val_loss: 5.1204 - val_mae: 4.9061\n",
            "Epoch 53/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.5491 - mae: 5.5458 - val_loss: 3.9502 - val_mae: 4.1649\n",
            "Epoch 54/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.7765 - mae: 5.7993 - val_loss: 8.2875 - val_mae: 8.6803\n",
            "Epoch 55/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 6.1408 - mae: 6.0222 - val_loss: 4.0379 - val_mae: 4.1450\n",
            "Epoch 56/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.7604 - mae: 5.7888 - val_loss: 11.2430 - val_mae: 11.0293\n",
            "Epoch 57/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.7277 - mae: 5.7783 - val_loss: 10.4495 - val_mae: 10.2781\n",
            "Epoch 58/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.7653 - mae: 5.7418 - val_loss: 5.7593 - val_mae: 5.9324\n",
            "Epoch 59/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.6798 - mae: 5.6952 - val_loss: 8.2465 - val_mae: 8.5770\n",
            "Epoch 60/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.7377 - mae: 5.7156 - val_loss: 7.7904 - val_mae: 8.1590\n",
            "Epoch 61/1000\n",
            "41/41 [==============================] - 0s 5ms/step - loss: 5.7063 - mae: 5.7035 - val_loss: 5.6462 - val_mae: 6.0099\n",
            "Epoch 62/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.6278 - mae: 5.5792 - val_loss: 4.6669 - val_mae: 4.4609\n",
            "Epoch 63/1000\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 5.7842 - mae: 5.7059 - val_loss: 4.6993 - val_mae: 4.9590\n",
            "Epoch 00063: early stopping\n",
            "[5.170092582702637, 5.180192947387695] 62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s39P_PvNW7Ig"
      },
      "source": [
        "# Saving and Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGNl23uFjEk-"
      },
      "source": [
        "# save model and architecture to single file\n",
        "from tensorflow.keras.models import save_model\n",
        "save_model(model,filepath=\"/content/drive/My Drive/Spring 2020 Materials/Week 1/Module1/Script and Data/My First NN Results/Saved_DNN_Model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIheCZFKWu0s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "8425c417-b9d7-4752-9262-c140aa02d051"
      },
      "source": [
        "# load and evaluate a saved model\n",
        "from tensorflow.keras.models import load_model\n",
        "# load model\n",
        "model = load_model('/content/drive/My Drive/Spring 2020 Materials/Week 1/Module1/Script and Data/My First NN Results/Saved_DNN_Model.h5')\n",
        "# summarize model.\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_66 (Dense)             (None, 64)                896       \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 8)                 520       \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 1,425\n",
            "Trainable params: 1,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}